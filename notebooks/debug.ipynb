{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../owl-vaes\")\n",
    "from generate_paired_dataset import WANDCAEProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:05:57,757 - INFO - WANDCAEProcessor 0 initialized\n"
     ]
    }
   ],
   "source": [
    "processor = WANDCAEProcessor(\n",
    "            gpu_id=0,\n",
    "            data_url=\"s3://cod-yt-latent-pairs/vids_pt/train\",\n",
    "            output_path=\"/home/developer/workspace/data/paired_test\",\n",
    "            batch_size=None,\n",
    "            shard_size_mb=10,\n",
    "            sequence_length=5,\n",
    "            num_workers=1,\n",
    "            dtype_str='bfloat16',\n",
    "            compile=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: TEST WAN input shape: torch.Size([1, 5, 3, 360, 640]) type: torch.uint8\n",
      "GPU 0: TEST WAN input shape: torch.Size([2, 5, 3, 360, 640]) type: torch.uint8\n",
      "GPU 0: TEST WAN input shape: torch.Size([4, 5, 3, 360, 640]) type: torch.uint8\n",
      "GPU 0: TEST WAN input shape: torch.Size([8, 5, 3, 360, 640]) type: torch.uint8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.get_max_batch_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:24,791 - INFO - GPU 0: Creating dataloader with batch_size=4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Creating dataloader with batch_size=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:27,930 - INFO - Found 19290 .pt files in bucket\n",
      "2025-07-03 12:06:27,931 - INFO - Prefetching file 1/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0000.pt\n",
      "2025-07-03 12:06:27,931 - INFO - Rank 0: Found 19290 files, prefetch_size=100\n",
      "2025-07-03 12:06:27,933 - INFO - GPU 0: Dataloader created successfully\n",
      "2025-07-03 12:06:27,935 - INFO - Starting iteration, initial queue size: 0\n",
      "2025-07-03 12:06:30,897 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0000.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:30,898 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0000.pt in 2.97s, generated 20 samples, queue size: 20/100\n",
      "2025-07-03 12:06:30,898 - INFO - Prefetching file 2/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0001.pt\n",
      "2025-07-03 12:06:30,937 - INFO - GPU 0: Processing batch 0, batch type: <class 'torch.Tensor'>\n",
      "2025-07-03 12:06:30,938 - INFO - GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:30,938 - INFO - GPU 0: Starting model preprocessing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:31,160 - INFO - GPU 0: Preprocessing complete. WAN shape: torch.Size([4, 5, 3, 512, 512]), DCAE shape: torch.Size([4, 5, 3, 360, 640])\n",
      "2025-07-03 12:06:31,161 - INFO - GPU 0: Starting model forward pass...\n",
      "2025-07-03 12:06:31,161 - ERROR - GPU 0: TEST WAN input shape: torch.Size([4, 5, 3, 512, 512]) type: torch.bfloat16\n",
      "2025-07-03 12:06:31,162 - ERROR - GPU 0: TEST DCAE input shape: torch.Size([4, 5, 3, 360, 640]) type: torch.bfloat16\n",
      "2025-07-03 12:06:36,702 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0001.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:36,703 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0001.pt in 5.80s, generated 20 samples, queue size: 36/100\n",
      "2025-07-03 12:06:36,703 - INFO - Prefetching file 3/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0002.pt\n",
      "2025-07-03 12:06:40,760 - INFO - GPU 0: Forward pass complete. WAN mean shape: torch.Size([4, 2, 16, 64, 64]), DCAE mean shape: torch.Size([4, 5, 128, 4, 4])\n",
      "2025-07-03 12:06:40,761 - INFO - GPU 0: Moved results to CPU\n",
      "2025-07-03 12:06:40,761 - INFO - GPU 0: Creating 4 samples...\n",
      "2025-07-03 12:06:40,762 - INFO - GPU 0: Successfully created and added 4 samples\n",
      "2025-07-03 12:06:40,762 - INFO - GPU 0: Processed 4 samples in 1 batches (current shard: 1.1 MB)\n",
      "2025-07-03 12:06:40,767 - INFO - GPU 0: Processing batch 1, batch type: <class 'torch.Tensor'>\n",
      "2025-07-03 12:06:40,768 - INFO - GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:40,768 - INFO - GPU 0: Starting model preprocessing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:40,978 - INFO - GPU 0: Preprocessing complete. WAN shape: torch.Size([4, 5, 3, 512, 512]), DCAE shape: torch.Size([4, 5, 3, 360, 640])\n",
      "2025-07-03 12:06:40,981 - INFO - GPU 0: Starting model forward pass...\n",
      "2025-07-03 12:06:40,981 - ERROR - GPU 0: TEST WAN input shape: torch.Size([4, 5, 3, 512, 512]) type: torch.bfloat16\n",
      "2025-07-03 12:06:40,981 - ERROR - GPU 0: TEST DCAE input shape: torch.Size([4, 5, 3, 360, 640]) type: torch.bfloat16\n",
      "2025-07-03 12:06:41,321 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0002.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:41,322 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0002.pt in 4.62s, generated 20 samples, queue size: 52/100\n",
      "2025-07-03 12:06:41,323 - INFO - Prefetching file 4/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0003.pt\n",
      "2025-07-03 12:06:42,975 - INFO - GPU 0: Forward pass complete. WAN mean shape: torch.Size([4, 2, 16, 64, 64]), DCAE mean shape: torch.Size([4, 5, 128, 4, 4])\n",
      "2025-07-03 12:06:42,976 - INFO - GPU 0: Moved results to CPU\n",
      "2025-07-03 12:06:42,977 - INFO - GPU 0: Creating 4 samples...\n",
      "2025-07-03 12:06:42,977 - INFO - GPU 0: Successfully created and added 4 samples\n",
      "2025-07-03 12:06:42,981 - INFO - GPU 0: Processing batch 2, batch type: <class 'torch.Tensor'>\n",
      "2025-07-03 12:06:42,982 - INFO - GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:42,983 - INFO - GPU 0: Starting model preprocessing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Batch shape: torch.Size([4, 5, 3, 360, 640]), dtype: torch.uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:43,234 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0003.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:43,234 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0003.pt in 1.91s, generated 20 samples, queue size: 68/100\n",
      "2025-07-03 12:06:43,235 - INFO - Prefetching file 5/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0004.pt\n",
      "2025-07-03 12:06:43,251 - INFO - GPU 0: Preprocessing complete. WAN shape: torch.Size([4, 5, 3, 512, 512]), DCAE shape: torch.Size([4, 5, 3, 360, 640])\n",
      "2025-07-03 12:06:43,251 - INFO - GPU 0: Starting model forward pass...\n",
      "2025-07-03 12:06:43,252 - ERROR - GPU 0: TEST WAN input shape: torch.Size([4, 5, 3, 512, 512]) type: torch.bfloat16\n",
      "2025-07-03 12:06:43,252 - ERROR - GPU 0: TEST DCAE input shape: torch.Size([4, 5, 3, 360, 640]) type: torch.bfloat16\n",
      "2025-07-03 12:06:45,079 - INFO - GPU 0: Forward pass complete. WAN mean shape: torch.Size([4, 2, 16, 64, 64]), DCAE mean shape: torch.Size([4, 5, 128, 4, 4])\n",
      "2025-07-03 12:06:45,079 - INFO - GPU 0: Moved results to CPU\n",
      "2025-07-03 12:06:45,080 - INFO - GPU 0: Creating 4 samples...\n",
      "2025-07-03 12:06:45,080 - INFO - GPU 0: Successfully created and added 4 samples\n",
      "2025-07-03 12:06:45,129 - INFO - GPU 0: Written shard 0 with 12 samples (3.2 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gpu_id': 0,\n",
       " 'total_processed': 12,\n",
       " 'total_batches': 3,\n",
       " 'final_shard_idx': 1,\n",
       " 'final_folder_idx': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:45,217 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0004.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-03 12:06:45,218 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0004.pt in 1.98s, generated 20 samples, queue size: 84/100\n",
      "2025-07-03 12:06:45,218 - INFO - Prefetching file 6/19290: s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt\n",
      "2025-07-03 12:06:47,238 - INFO - Successfully loaded s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt, tensor shape: torch.Size([101, 3, 360, 640]), dtype: torch.uint8\n",
      "2025-07-03 12:06:47,238 - WARNING - Queue full, dropping sample from s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt\n",
      "2025-07-03 12:06:47,239 - WARNING - Queue full, dropping sample from s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt\n",
      "2025-07-03 12:06:47,239 - WARNING - Queue full, dropping sample from s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt\n",
      "2025-07-03 12:06:47,239 - WARNING - Queue full, dropping sample from s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt\n",
      "2025-07-03 12:06:47,240 - INFO - Processed s3://cod-yt-latent-pairs/vids_pt/train/0000/0005.pt in 2.02s, generated 20 samples, queue size: 100/100\n"
     ]
    }
   ],
   "source": [
    "processor.process_dataset(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
