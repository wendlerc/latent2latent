{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../owl-vaes')\n",
    "sys.path.append('../')\n",
    "import tarfile\n",
    "import io\n",
    "import torch\n",
    "\n",
    "path = \"/home/developer/workspace/data/vast/0000.tar\"\n",
    "\n",
    "def process_tensor_file(tar, base_name, suffix):\n",
    "    try:\n",
    "        f = tar.extractfile(f\"{base_name}.{suffix}.pt\")\n",
    "        if f is not None:\n",
    "            tensor_data = f.read()\n",
    "            tensor = torch.load(io.BytesIO(tensor_data))\n",
    "            return tensor\n",
    "    except:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "with tarfile.open(path, 'r') as tar:\n",
    "    mean_wan = process_tensor_file(tar, '0002', 'wan')\n",
    "    mean_dcae = process_tensor_file(tar, '0002', 'dcae')\n",
    "\n",
    "print(mean_wan.shape, mean_dcae.shape)\n",
    "print(mean_wan.dtype, mean_dcae.dtype)\n",
    "print(mean_wan.min(), mean_wan.max())\n",
    "print(mean_dcae.min(), mean_dcae.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_wan = True\n",
    "from diffusers import AutoencoderKLWan\n",
    "from owl_vaes.configs import ResNetConfig\n",
    "from owl_vaes.models.dcae import DCAE\n",
    "import torch\n",
    "if check_wan:\n",
    "    if len(mean_wan.shape) == 4:\n",
    "        mean_wan = mean_wan.unsqueeze(0)\n",
    "        print(mean_wan.shape)\n",
    "    vae = AutoencoderKLWan.from_pretrained(\n",
    "        \"Wan-AI/Wan2.1-VACE-14B-diffusers\",\n",
    "        subfolder=\"vae\",\n",
    "        torch_dtype=torch.bfloat16  # Optional: use half precision\n",
    "    )\n",
    "    vae.encoder = None \n",
    "    # Move to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    vae = vae.cuda()\n",
    "    vae.compile()\n",
    "    with torch.no_grad():\n",
    "        out = vae.decode(mean_wan.bfloat16().cuda().permute(0,2,1,3,4))\n",
    "        recon_vid = out.sample.permute(0,2,1,3,4)\n",
    "        recon_vid = recon_vid[0]\n",
    "else:\n",
    "    cfg = ResNetConfig(\n",
    "        sample_size=[360,640],\n",
    "        channels=3,\n",
    "        latent_size=4,\n",
    "        latent_channels=128,\n",
    "        noise_decoder_inputs=0.0,\n",
    "        ch_0=256,\n",
    "        ch_max=2048,\n",
    "        encoder_blocks_per_stage = [4, 4, 4, 4, 4, 4, 4],\n",
    "        decoder_blocks_per_stage = [4, 4, 4, 4, 4, 4, 4]\n",
    "    )\n",
    "    vae = DCAE(cfg)\n",
    "    vae.load_state_dict(torch.load(\"/home/developer/workspace/models/cod_128x.pt\"))\n",
    "    vae.encoder = None\n",
    "    vae.bfloat16().cuda()\n",
    "    print(mean_dcae.shape)\n",
    "    # Process in batches to avoid memory issues\n",
    "    batch_size = 4\n",
    "    recon_vid_list = []\n",
    "    \n",
    "    for i in range(0, mean_dcae.shape[0], batch_size):\n",
    "        batch = mean_dcae[i:i+batch_size].bfloat16().cuda()\n",
    "        with torch.no_grad():\n",
    "            batch_recon = vae.decoder(batch)\n",
    "        recon_vid_list.append(batch_recon.cpu())\n",
    "    \n",
    "    recon_vid = torch.cat(recon_vid_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lat2lat.utils import create_video_visualization, export_video_as_gif\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Example usage with your reconstructed video\n",
    "print(\"Creating video visualizations...\")\n",
    "\n",
    "# 1. Animated playback\n",
    "print(\"\\n1. Creating animated playback...\")\n",
    "anim, video_np = create_video_visualization(recon_vid, \"Reconstructed Video Playback\")\n",
    "display(HTML(anim.to_jshtml()))\n",
    "\n",
    "# 2. Export as GIF\n",
    "print(\"\\n2. Exporting as GIF...\")\n",
    "export_video_as_gif(video_np, \"reconstructed_video.gif\", fps=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
